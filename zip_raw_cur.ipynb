{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.auth import HTTPBasicAuth\n",
    "from impala.dbapi import connect\n",
    "from datetime import datetime\n",
    "from pyhive import hive\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Variables'''\n",
    "## Atlas dev\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "credentials = HTTPBasicAuth('atlasadmin', 'xNB8lZ!Dut')\n",
    "atlas_urls = [\"172.30.213.141\",\"172.30.213.142\"]\n",
    "atlas_port = 31000\n",
    "\n",
    "## Hive dev\n",
    "hive_host = 'edh-master-01d.root.corp'\n",
    "hive_port = 10000\n",
    "hive_user = 'admin'\n",
    "\n",
    "\n",
    "## Impala dev\n",
    "impala_host = '172.30.213.211'\n",
    "impala_port = 21050\n",
    "impala_user = 'admin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIVE\n",
    "def describe_table( hive_database, table_name ):\n",
    "    #Creo la conexión y obtengo el cursos\n",
    "    hive_conn = hive.connect(host=hive_host, port=hive_port, username=hive_user, database=hive_database)\n",
    "    hive_cursor = hive_conn.cursor()\n",
    "\n",
    "    # Obtengo el create\n",
    "    hive_cursor.execute(f'DESCRIBE {hive_database}.{table_name}')\n",
    "    databases = hive_cursor.fetchall()\n",
    "    \n",
    "    return databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json_completo.json') as f:\n",
    "    file = f.read()\n",
    "    json_file = json.loads(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print json completo\n",
    "print(json.dumps(json_file, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Así es el formato de cada registro en el JSON\n",
    "\"de_bsj_1raw.sfb_aampr\": {\n",
    "    \"database\": \"de_bsj_1raw\",\n",
    "    \"table_name\": \"sfb_aampr\",\n",
    "    \"create_table\": \"CREATE EXTERNAL TABLE `de_bsj_1raw`.`sfb_aampr`(   `glb_dtime` string COMMENT '',    `aco_conce` string COMMENT 'C\\u00f3digo de concepto',    `aco_produ` string COMMENT 'C\\u00f3digo de producto',    `acoidprod` string COMMENT 'Identificaci\\u00f3n del producto',    `ase_essfb` string COMMENT 'Fecha de vencimiento del producto',    `aseprocom` string COMMENT 'Fecha de vigencia del producto',    `dco_moned` string COMMENT 'Nombre del producto',    `afevenpro` string COMMENT 'Nro. de Campo c.467',    `afevigpro` string COMMENT 'Nro. de Campo gtia.',    `ano_produ` string COMMENT 'Nro. de Campo lisol',    `anu_ca467` string COMMENT 'Factor de ponderaci\\u00f3n',    `anu_campo` string COMMENT 'Fecha de vencimiento del producto en formato relativa',    `anu_lisol` string COMMENT 'Fecha de vigencia del producto en formato relativa',    `apofacpon` string COMMENT 'Se\\u00f1al que indica si es un producto SFB',    `arevenpro` string COMMENT 'Se\\u00f1al de si Controla productos privados',    `arevigpro` string COMMENT 'Se\\u00f1al es producto cta comitente',    `estado` string COMMENT 'C\\u00f3digo de moneda',    `ase_priva` string COMMENT 'Estado') COMMENT 'MAESTRO DE PRODUCTOS GENERAL' PARTITIONED BY (    `fecha_proceso` varchar(8)) ROW FORMAT SERDE    'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'  STORED AS INPUTFORMAT    'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'  OUTPUTFORMAT    'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat' LOCATION   'hdfs://nameservice1/user/admin/dev/bsj/01-raw/sfb/productos/plazo_fijo/sfb_aampr' \",\n",
    "    \"associated_term\": \"aampr\",\n",
    "    \"loading_query\": null,\n",
    "    \"affected_tables\": [\n",
    "      \"de_bsj_2cur.productos_aampr\"\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['# Partition Information', '# col_name', '']\n",
    "\n",
    "def es_garbage( campo, opciones ):\n",
    "    return campo in opciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares_raw_cur = []\n",
    "\n",
    "for table_raw in json_file.keys():\n",
    "    if '1raw' in table_raw:\n",
    "        db_raw, table_name_raw = table_raw.split('.')\n",
    "        # Obtenemos lista de tablas afectadas\n",
    "        list_affected_tables = json_file[table_raw]['affected_tables']\n",
    "        # Si afecta más de una tabla, debemos obtener solo la que posea la misma fuente en el nombre en curado\n",
    "        if len(list_affected_tables)>1:\n",
    "            source = table_name_raw.split('_')[-1]\n",
    "            # Filtra la tabla que contiene la fuente\n",
    "            cur_table = [t for t in list_affected_tables if source in t]\n",
    "            cur_table = cur_table[0]\n",
    "        if len(list_affected_tables)>0:\n",
    "            # Si tiene 1 solo elemento, entonces esa es la tabla en curado\n",
    "            cur_table = list_affected_tables[0]\n",
    "        \n",
    "        # Si llgué acá es porque tengo la tabla en raw + cur\n",
    "        db_cur, table_name_cur = cur_table.split('.')\n",
    "\n",
    "        create_raw = describe_table(db_raw, table_name_raw) \n",
    "        create_cur = describe_table(db_cur, table_name_cur) \n",
    "        if len(create_raw) == len(create_cur):\n",
    "            #La cantidad de campos es igual\n",
    "            #Zippeamos campo (raw, cur)\n",
    "            pares_raw_cur.append( [(f'{table_raw}.{tupla_raw[0]}', f'{cur_table}.{tupla_cur[0]}') for tupla_raw, tupla_cur in zip(create_raw, create_cur) if not es_garbage(tupla_raw[0], options)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar la lista anidada\n",
    "lista_aplanada = [tupla for sublist in pares_raw_cur for tupla in sublist]\n",
    "\n",
    "# Crear un DataFrame a partir de la lista aplanada\n",
    "df = pd.DataFrame(lista_aplanada, columns=['nombre_campo_raw', 'nombre_campo_cur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_procesada/mapeo_campos_raw_cur.csv', sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
